
# [OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online Ensembling](https://arxiv.org/abs/2309.12659)

----

<img width="1366" alt="Screenshot 2025-04-02 at 1 02 10 AM" src="https://github.com/user-attachments/assets/2ff2b8be-b73b-4ec5-a65a-29b0eeed5680" />

-----

### [GitHub代码](https://github.com/yfzhang114/OneNet)

-----

## **研究背景**

该论文提出了一种名为 OneNet 的在线集成框架，旨在应对时间序列预测中的概念漂移问题。OneNet 通过动态集成两个模型：

1） 时间依赖模型：捕捉时间维度上的依赖关系。

2） 跨变量依赖模型：建模变量之间的交叉依赖。

通过引入强化学习机制，OneNet 在传统的在线凸优化框架中动态调整两个模型的权重，从而实现对概念漂移的快速适应。实验结果显示，OneNet 在多个基准数据集上将在线预测误差降低了超过 50% 。


## 算法

<img width="658" alt="Screenshot 2025-05-21 at 11 39 19 AM" src="https://github.com/user-attachments/assets/86f49544-300a-4546-8e22-4deeeab4689b" />

#### （1） 模型初始化：

- 初始化两个子模型：一个专注于时间依赖，另一个专注于跨变量依赖。

- 初始化强化学习代理，用于动态调整模型权重。

#### （2） 在线学习过程（对于每一个时间步）：

2.1 数据输入：接收新的时间序列数据。

2.2 子模型预测：两个子模型分别对当前数据进行预测。

2.2 权重调整：

- 强化学习代理根据当前预测性能和历史表现，调整两个子模型的权重。

- 使用在线凸优化方法，确保权重调整的稳定性和收敛性。

2.3 集成预测：根据调整后的权重，对两个子模型的预测结果进行加权，得到最终预测。

2.4 模型更新：根据新的数据和预测误差，更新子模型和强化学习代理的参数。

#### （3） 持续迭代：重复上述过程，持续适应数据的概念漂移。

本算法就是让两个不同思路的预测器“合体”，每次做决策时自动认为“谁靠谱信谁多一点”，并随着时间不断自我修正和优化预测效果。

## 应用

虽然 OneNet 主要针对时间序列预测中的概念漂移问题，但其在线学习和动态集成的机制对增量学习领域具有启发意义：

1. 在线适应能力：OneNet 能够在数据流中实时更新模型，适应新的数据分布，符合增量学习中对模型持续学习的要求。

2. 避免灾难性遗忘：通过集成多个子模型，OneNet 在引入新知识的同时，保留了旧知识，减缓了灾难性遗忘的问题。

3. 动态权重调整：强化学习机制使模型能够根据当前任务的需求，动态调整不同子模型的贡献，有助于在多任务增量学习中实现任务间的平衡。

