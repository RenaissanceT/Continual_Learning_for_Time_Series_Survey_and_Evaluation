
# [OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online Ensembling](https://arxiv.org/abs/2309.12659)

----

<img width="1366" alt="Screenshot 2025-04-02 at 1 02 10 AM" src="https://github.com/user-attachments/assets/2ff2b8be-b73b-4ec5-a65a-29b0eeed5680" />

-----

### [GitHub代码](https://github.com/yfzhang114/OneNet)

-----

**领域** : 

属于增量学习，针对时间序列预测中的概念漂移问题

**分类** : 
、
属于增量学习中的**域增量学习**

**多任务** : 

实验部分涉及多个数据集

**场景** : 

设定场景是**在线时间序列预测**，目标是通过增量学习方法提高对概念漂移的适应能力。属于在线学习，因为模型需要随着数据的变化进行动态调整

**问题** :

研究的问题是如何在概念漂移的情况下进行稳定学习，域的划分基于 **数据流的概率分布变化**

**方法** : 

提出了一种**OneNet框架**，该方法通过 **动态组合两个模型**（一个关注时间维度的依赖关系，另一个关注跨变量的依赖关系）来优化模型适应性

细分属于**预测**，因为它能够时间序列预测的准确性， 属于**Replay Methods**

**为什么** : 

采用OneNet框架的原因是通过动态组合模型，能够更有效地适应数据流的变化，提高时间序列预测的长期稳定性

-----

## **研究背景**

该论文提出了一种名为 OneNet 的在线集成框架，旨在应对时间序列预测中的概念漂移问题。OneNet 通过动态集成两个模型：

1） 时间依赖模型：捕捉时间维度上的依赖关系。

2） 跨变量依赖模型：建模变量之间的交叉依赖。

通过引入强化学习机制，OneNet 在传统的在线凸优化框架中动态调整两个模型的权重，从而实现对概念漂移的快速适应。实验结果显示，OneNet 在多个基准数据集上将在线预测误差降低了超过 50% 。

作者动态更新和组合两个模型，一个模型专注于跨时间维度的依赖关系建模，另一个专注于跨变量依赖关系。我们的方法将基于强化学习的方法整合到传统的在线凸编程框架中，允许两个模型与动态调整的权重进行线性组合。OneNet 解决了经典在线学习方法的主要缺点，这些方法往往在适应概念漂移方面进展缓慢。

## 算法

我们介绍了 OneNet，这是一种用于在线时间序列预测的双流架构，它使用在线凸编程集成两个模型的输出。OneNet 利用变量无关模型的稳健性来处理概念漂移，同时还捕获不同变量之间的相互依赖关系以提高预测准确性。此外，我们提出了一种基于 RL 的在线学习方法，以减轻传统 OCP 算法的局限性，并通过实证和理论分析证明其有效性。

<img width="1258" alt="Screenshot 2025-05-21 at 11 39 19 AM" src="https://github.com/user-attachments/assets/86f49544-300a-4546-8e22-4deeeab4689b" />

![image](https://github.com/user-attachments/assets/2892ee20-f08e-4863-a19f-62553b552fca)

（（a） OneNet 通过跨时间和跨变量分支处理多变量数据，每个分支负责捕获不同的方面。这两个分支的权重由 OCP 块生成，训练时只有黑色箭头需要执行。（b） OCP 块通过利用指数梯度下降 （EGD） 的长期历史和离线强化学习 （RL） 的短期历史来生成集成权重）

#### （1） 模型初始化

- 初始化两个子模型：一个专注于时间依赖，另一个专注于跨变量依赖。

- 初始化强化学习代理，用于动态调整模型权重。
  
#### （2） 在线学习过程（对于每一个时间步）

2.1 数据输入：接收新的时间序列数据。

2.2 子模型预测：两个子模型分别对当前数据进行预测。

2.2 权重调整：

强化学习代理根据当前预测性能和历史表现，调整两个子模型的权重。

使用在线凸优化方法，确保权重调整的稳定性和收敛性。

2.3 集成预测：根据调整后的权重，对两个子模型的预测结果进行加权，得到最终预测

2.4 模型更新：根据新的数据和预测误差，更新子模型和强化学习代理的参数。

#### （3） 持续迭代：重复上述过程，持续适应数据的概念漂移。

本算法就是让两个不同思路的预测器“合体”，每次做决策时自动认为“谁靠谱信谁多一点”，并随着时间不断自我修正和优化预测效果。

## 应用

虽然 OneNet 主要针对时间序列预测中的概念漂移问题，但其在线学习和动态集成的机制对增量学习领域具有启发意义：

1. 在线适应能力：OneNet 能够在数据流中实时更新模型，适应新的数据分布，符合增量学习中对模型持续学习的要求。

2. 避免灾难性遗忘：通过集成多个子模型，OneNet 在引入新知识的同时，保留了旧知识，减缓了灾难性遗忘的问题。

3. 动态权重调整：强化学习机制使模型能够根据当前任务的需求，动态调整不同子模型的贡献，有助于在多任务增量学习中实现任务间的平衡。

##  结论

通过我们对具有概念漂移的高级预测模型的行为的调查，我们发现跨时间模型在变量数量较多时表现出更高的稳健性，但在变量数量较少时，跨时间模型不如可以建模变量依赖关系的模型。此外，由于概念漂移的发生，这个问题变得更具挑战性，因为在整个在线预测过程中，两种模型偏差的数据偏好都在动态变化，这使得单个模型难以克服。为此，我们提出了 OneNet 模型，它通过 OCP 利用了两种模型的优势。此外，我们建议通过离线强化学习来学习额外的短期权重，以缓解传统策略学习算法中常见的慢切换现象。我们广泛的实验表明，OneNet 能够有效地处理各种类型的概念漂移，并且在预测性能方面优于以前的方法。

我们还发现，实例归一化增强了概念漂移下的模型稳健性，但在某些情况下会阻碍模型快速适应新分布的能力。这促使进一步探索是否存在一种可以减轻分布变化同时能够快速适应不断变化的概念的归一化技术。此外，尽管我们设计了 OneNet 的简化版本来解决引入额外参数和推理时间的问题，但有可能采用更有效的适应方法，例如利用来自 NLP/CV 社区的提示和高效调整方法，以避免重新训练完整模型。

