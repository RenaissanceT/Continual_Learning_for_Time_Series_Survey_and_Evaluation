
# [Mode Connections For Clinical Incremental Learning: Lessons From The COVID-19 Pandemic](https://www.medrxiv.org/content/10.1101/2023.05.05.23289583v1.full)

----

<img width="1366" alt="Screenshot 2025-04-02 at 12 49 15 AM" src="https://github.com/user-attachments/assets/28eb95ac-e4af-476c-8005-c3f0ba0b8a7b" />

-----

## **研究背景**

作者提出利用 **模式连接 mode connections**，即在神经网络参数空间中连接两个最小化点（模式）的低损失路径，来构建一个包含多个模式的网络。通过在现有模式和随机点之间学习一条低损失路径，并在该路径上找到适合新领域的模式，从而实现模型的增量更新，而无需修改原有模型的权重。该方法在牛津大学医院收集的COVID-19前后数据上进行了验证，展示了其在处理临床数据分布漂移方面的有效性。

![image](https://github.com/user-attachments/assets/423cec71-0a3a-41ef-a554-1aa4eeaf840b)

本文将增量或持续学习概念化为避免灾难性遗忘的增量模式网络, 拟议的框架为新域提供了一条可能的最小化路径。从这些低损耗路径中采样的模式可以用作集成，因此可以获得不确定性较小的预测。该方法通过在神经网络参数空间中连接两个最小化点（模式）的低损失路径，来构建一个包含多个模式的网络，从而实现模型的增量更新，而无需修改原有模型的权重。

## 算法（见上方图示）

1. **初始模式设定**：将当前已部署的模型参数设为模式 $\theta_A$。

2. **路径学习**：在新领域的数据上，学习从 $\theta_A$ 到一个随机点 $\theta_R$ 的低损失路径 $\gamma_{\theta_A \rightarrow \theta_R}$，该路径可通过贝塞尔曲线等方式建模。

3. **新模式确定**：在路径 $\gamma_{\theta_A \rightarrow \theta_R}$ 上，找到在新领域验证集上损失最小的点 $\theta_B$，作为新领域的模式。

4. **模式网络扩展**：将路径 $\gamma_{\theta_A \rightarrow \theta_B}$ 添加到模式网络中，实现对新领域的增量学习。

5. **多领域扩展**：对于后续的新领域，重复上述步骤，逐步构建包含多个模式的网络。

## 模型架构与参数设置（Model Architecture and Parameter Setting）

DNN with 308 nodes → ReLU activation → Dropout with 0.25 rate → DNN with 231 nodes → ReLU activation → Dropout with 0.25 rate → DNN with 1 node → Sigmoid activation

- 模型使用 Adam 优化器进行训练，学习率固定为 $10^{-4}$，批次大小为 2048。
  
- 为实现 GDumb 和 GEM 方法，我们在每个新任务中保留来自先前领域的 5000 个样本（每类各 2500 个）作为缓冲区。

## 结论

本文提出了一种基于模式连接的增量学习方法。所提出的方法在学习新模式或领域时不会遭受灾难性的遗忘。OUH 数据的实验结果突出了所提出的方法的潜在好处。尽管本文提供了强有力的证据支持模式网络作为增量学习框架，但需要进行彻底的调查来分析这种方法在更具挑战性和多样化条件下的行为。需要更多的工作来降低所提出的方法的计算和空间复杂性。此外，我们没有强调用于降低预测不确定性的模式连接的集成方面。未来的工作将处理这些方面以改进所提出的方法。
