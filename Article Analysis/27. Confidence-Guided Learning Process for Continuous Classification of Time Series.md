
# [Confidence-Guided Learning Process for Continuous Classification of Time Series](https://arxiv.org/abs/2208.06883#:~:text=Thus%2C%20we%20propose%20a%20novel%20Confidence-guided%20method%20for,and%20the%20self-confidence%20to%20control%20the%20learning%20duration.)

----

<img width="1366" alt="Screenshot 2025-04-02 at 12 39 21 AM" src="https://github.com/user-attachments/assets/1815329c-8ee9-4a22-98f6-2e8187d9f9b6" />

----

提出了一个新概念：时间序列的连续分类 （CCTS）。CCTS 存在两个悬而未决的问题：（1） 数据整理。时间序列是一种动态数据。随着时间的推移，它会演变出多个发行版。多分布的划分会直接影响分类精度;（2） 模型训练策略。当模型学习多分布式数据时，它总是会忘记主分布中的旧分布或过拟合。不同的数据学习顺序将导致不同的模型性能。我们发现，模型学习多重分布的过程可以类似于人类学习多重知识的过程。因此，我们为 CCTS 提出了一种新的置信度指导方法来安排数据和安排训练，名为 C3TS 。它模仿了人类在学习过程中的客观自信和交替的自信，这由邓宁-克鲁格效应所描述。具体来说，我们定义了一个基于重要性的目标置信度来排列和重放数据，并设计了一个基于不确定性的自信心来控制训练持续时间。
 
C3TS 提出了一个以 **信心 Confidence** 为核心的、兼顾人类类比学习机制与深度模型特性的训练流程：模拟人类「学-忘-复习-掌握」的过程；在多个现实时间序列数据集（地震、降雨、COVID-19、败血症）中验证有效性；尤其适合需要连续监测、具有时间演化性的任务（如ICU生命体征、自然灾害监测等）。C3TS 提出了一种新的时间序列分类任务：**连续时间序列分类（CCTS）**，其目标是在每一个时间点对时间序列进行预测，而不仅仅是在最后时间点做一次分类。

为解决其中两个关键挑战：

1. **数据多分布划分问题**
2. **模型在多阶段学习中的遗忘与过拟合问题**

![image](https://github.com/user-attachments/assets/43c578f6-0ddc-40ee-a80c-31a02e5257fa)

作者设计了模仿人类“信心演化过程”的训练框架：**C3TS（Confidence-guided Continuous Time Series Classification）**，引入 **客观信心** 和 **自我信心** 两个概念以引导训练。

### 概念

- **客观信心（Objective-confidence）**：表示模型对不同样本学习情况的“外部评估”，用于决定哪些样本需要重放（Replay）。
- **自我信心（Self-confidence）**：表示模型对当前数据分布是否学会的“内部评估”，用于判断是否停止当前阶段训练。

### 算法
```
输入：原始数据集 S，初始模型 f。
输出：训练好的模型 fM。

步骤一：数据安排（Data Arrangement）
1. 从每条时间序列生成各个时间点的子序列 {X1:t}
2. 使用预训练模型计算每个样本的“数据不确定性（Udata）”
3. 将数据按 Udata 分成 M 个子集（baby steps），用于模拟课程学习顺序

步骤二：信心引导的训练过程（Confidence-Guided Training）
对每个子集 Dm：
  - 在训练过程中计算样本重要性系数 βi，识别应重放的重要样本
  - 训练到 self-confidence 达到阈值（即总不确定性下降到稳定）
  - 转向下一个数据子集 Dm+1，并将重要旧样本加入训练缓冲区
```

### 问题

| 问题类别             | 描述                                                                 |
|----------------------|----------------------------------------------------------------------|
| 依赖初始模型性能     | 初始训练影响数据划分，初始模型差时可能误导整个训练路径               |
| 不确定性计算代价高   | Monte Carlo Dropout 等方法开销大，训练与推理都较慢                   |
| 超参数多             | 如 M、ε、early stop 判断间隔，需手动调参                              |
| 不支持类增量学习     | 当前方法仅适用于单任务多分布，无法应对新类别的增量学习               |

### 改进

| 问题               | 改进方向                                                             |
|--------------------|----------------------------------------------------------------------|
| 初始模型依赖强     | 使用教师-学生架构或集成模型获取更稳健的初始 β/Udata                  |
| 不确定性计算开销大 | 采用 evidential learning 或 softmax entropy 替代 MC Dropout          |
| 自动超参数优化     | 使用 meta-learning 或强化学习调整 M、ε 等参数                         |
| 类别增量扩展       | 融合类增量方法，如 prototype replay 或可扩展分类头                   |






