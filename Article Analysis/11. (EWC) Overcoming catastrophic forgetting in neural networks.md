# EWC - [Overcoming catastrophic forgetting in neural networks](https://arxiv.org/abs/1612.00796)

---

<img width="1139" alt="Screen Shot 2024-10-11 at 12 51 10 PM" src="https://github.com/user-attachments/assets/047eab2a-bb33-4127-a310-7de0d5b7dc49">

---

# 核心要点

## 1. EWC的方法

Elastic Wight Consolidation 弹性权重巩固 (具体通过对**重要权重施加惩罚**来保持其在一定范围内，保护旧任务的知识)

### 1. **重要性权重的计算**

- EWC通过计算 **Fisher信息矩阵** 来确定每个权重对任务性能的重要性。**Fisher信息** 反映了参数在当前任务下的敏感性。

- 重要的权重具有较高的 **Fisher值**，这些权重在学习新任务时需要被保护。

### 2. **EWC方法**

- EWC通过**选择性地减缓对某些权重的学习**，保护与旧任务相关的重要权重，以便在学习新任务时不遗忘旧任务的知识。

- EWC基于人脑的生物机制，通过“固化”重要权重来实现对旧知识的保护。

### 3. **实验验证**

- 通过在MNIST数据集和多个Atari游戏中进行实验，证明了EWC在连续学习中的有效性。

- 与传统的随机梯度下降（SGD）和L2正则化方法相比，EWC显著减少了遗忘。
  
<img width="924" alt="Screen Shot 2024-10-11 at 12 15 17 PM" src="https://github.com/user-attachments/assets/fa07abac-1667-4c28-a0e7-7c5a7af6d407">

## 2. EWC的算法

### 1. 算法原理

EWC的核心思想是为每个权重引入**一个二次惩罚项**，**该惩罚项与该权重对旧任务的重要性成正比**。通过控制网络参数向旧参数附近 **尽量不移动**，从而保持对旧任务的良好表现。

### 2. 算法步骤

1. **计算Fisher信息矩阵**：

Fisher信息矩阵（F）用于量化每个权重对当前任务的贡献，F的对角线元素 反映了各参数的重要性。
   
2. **定义损失函数**：

在学习新任务时，损失函数是：

<img width="924" alt="Screen Shot 2024-10-11 at 12 24 22 PM" src="https://github.com/user-attachments/assets/b2e52eab-781b-4993-a55e-942e6a69e470">

论文里面的定义公式：

<img width="935" alt="Screen Shot 2024-10-11 at 12 27 36 PM" src="https://github.com/user-attachments/assets/0e405cb0-f1da-4237-bf37-af3880f57209">

<img width="935" alt="Screen Shot 2024-10-11 at 12 38 54 PM" src="https://github.com/user-attachments/assets/1ffd9a7a-7d41-4122-9673-fcd0e6fdfcff">

3. **参数更新**：
   
- 在训练新任务B时，EWC约束了与任务A相关的重要权重，使得这些权重不易发生大幅变化。
  
- 在训练新任务时，EWC通过在优化过程中加入这个惩罚项来减缓对旧任务重要权重的更新。
  
- 这就像给重要的权重加上一根“弹簧”，使其在学习新任务时不被过度调整。
     
### 3. 在避免灾难性遗忘中的应用

- EWC允许网络在学习新任务时，能够保持对旧任务的记忆。
  
- 实验表明，EWC能够有效地在多任务学习中共享网络权重，同时又减少了遗忘的发生。

## 3. EWC的避免灾难性遗忘

1. **在监督学习中的应用 EWC allows continual learning in a supervised learning context**：

   - EWC通过在多个分类任务之间进行训练，能有效保持旧任务的性能。实验结果显示，EWC显著减少了在学习新任务时对旧任务性能的损失。

2. **在强化学习中的应用 EWC allows continual learning in a reinforcement learning context**：
   
   - 在如Atari游戏等复杂的强化学习环境中，EWC能够帮助代理记住之前学习的策略，而不会因学习新游戏而遗忘旧游戏的知识。
     
   - 通过在多个游戏中共享网络参数，EWC确保了对旧任务知识的保护，同时允许在新任务上进行有效学习。

----

## 核心概念：二次惩罚项

二次惩罚项是一种在优化问题中常用的正则化技术，目的是防止模型过拟合。它通过在损失函数中引入额外的惩罚项来实现。

<img width="924" alt="Screen Shot 2024-10-11 at 12 22 44 PM" src="https://github.com/user-attachments/assets/33dcae58-2425-4c3b-ae96-d6518b85259b">

### 作用：

1. 通过增加二次惩罚项，优化过程会更倾向于保持参数在某个范围内，从而减少模型的复杂度，降低过拟合的风险。

2. 在EWC中，二次惩罚项用于约束重要权重，使得这些权重在学习新任务时不会大幅改变，从而保护旧任务的知识。

3. 二次惩罚项的引入可以减小模型对某些参数的学习，使得这些参数保持在一个较小的范围内，从而保护旧任务的知识。

----

## 核心概念：Fisher信息矩阵

Fisher信息矩阵是一种用于描述统计模型参数不确定性的工具。它是一个正定矩阵，包含了模型参数的第二阶导数信息，Fisher信息矩阵则用于量化参数的重要性，指导模型的优化过程。

<img width="924" alt="Screen Shot 2024-10-11 at 12 23 49 PM" src="https://github.com/user-attachments/assets/dd1a8266-bd42-4b48-b540-4890af68a1df">

### 作用：

1. Fisher信息矩阵的对角线元素提供了关于参数估计精度的信息。值越大，表示该参数对模型输出的影响越大，因此我们对其估计越精确。

2. 在EWC中，Fisher信息矩阵 **用于确定哪些权重对旧任务的重要**性，以便在训练新任务时通过惩罚项保护这些重要权重。

### Fisher信息矩阵的主要属性包括：

1. **重要性度量**：Fisher信息矩阵的对角线元素表示每个参数对模型的影响程度，值越大说明该参数对模型性能的贡献越大。
   
2. **优化指引**：在优化过程中，Fisher信息矩阵可以用来调整学习率，以便对重要参数采取较小的学习步长，对不重要的参数采取较大的步长，从而提高学习效率。

---

## 核心概念：对数似然函数

对数似然函数通常是用于描述模型对给定数据的拟合程度的函数。对数似然函数是根据模型输出和实际标签计算的，反映了模型对训练数据的拟合程度。EWC中使用的对数似然函数的具体形式取决于所用的模型和损失函数。具体来说，假设我们有一个训练数据集 {x1, x2, ..., xn} 对数似然函数可以表示为：

<img width="935" alt="Screen Shot 2024-10-11 at 12 35 11 PM" src="https://github.com/user-attachments/assets/a5ae42d8-402e-4985-8ed1-21c102f2206d">

----

# 精读笔记

### 1. 什么是“灾难性遗忘”？
- **答案**：灾难性遗忘是指神经网络在学习新任务时，之前学习的任务的知识被迅速遗忘的现象。
- **解释**：例如，假设一个模型先学习识别猫的图片，然后再学习识别狗的图片。通常，在学习狗的过程中，模型对猫的识别能力会显著下降。

### 2. 为什么灾难性遗忘是实现人工智能的重要障碍？
- **答案**：因为在实际应用中，AI系统需要能够连续学习多个任务，而不丢失对之前任务的能力。
- **解释**：例如，在自动驾驶中，汽车需要不断学习新的驾驶情境，同时保持对以前学会的路况的理解。

### 3. 这篇论文中提出了什么解决灾难性遗忘的方法？
- **答案**：提出了“弹性权重固化”（EWC）的方法，通过在训练新任务时保护重要权重，减少对旧任务知识的遗忘。
- **解释**：可以想象成在学习新东西时，保留旧知识的同时，增加新知识的能力。

### 4. EWC如何确定哪些权重重要？
- **答案**：通过计算Fisher信息矩阵来确定权重的重要性。
- **解释**：Fisher信息量度了参数对损失函数的影响，越重要的权重，其Fisher值越大。

### 5. Fisher信息矩阵的作用是什么？
- **答案**：Fisher信息矩阵用于量化各个参数对模型性能的影响，帮助EWC选择哪些参数在学习新任务时需要保护。
- **解释**：如果某个权重的重要性较高，EWC将更强地约束这个权重，以防其在新任务训练中发生变化。

### 6. EWC在监督学习和强化学习中如何应用？
- **答案**：EWC可以用于监督学习任务的逐步训练，也可以在强化学习中保护先前任务的知识。
- **解释**：在监督学习中，可以在多个分类任务间进行训练，而在强化学习中，可以在多个游戏中学习而不丢失之前游戏的知识。

### 7. 在实验中，EWC与传统的随机梯度下降（SGD）相比有什么优势？
- **答案**：EWC能显著减少在学习新任务时对旧任务性能的损失，而SGD通常会导致灾难性遗忘。
- **解释**：例如，使用EWC时，网络在学习新任务时，能保持对旧任务的高准确率。

### 8. 论文中提到的“多任务学习”与EWC有什么区别？
- **答案**：多任务学习是在同一时间内使用多个任务的数据进行训练，而EWC是在任务顺序学习中保护旧任务知识。
- **解释**：多任务学习需要同时访问所有任务的数据，而EWC允许任务逐步学习。

### 9. EWC是如何实施的？
- **答案**：通过在损失函数中添加一个关于旧任务的重要性权重的二次惩罚项。
- **解释**：这相当于给重要的权重加上一根“弹簧”，防止其过度变动。

### 10. 在EWC中，λ的作用是什么？
- **答案**：λ控制旧任务的重要性，相当于调整保护旧任务知识的强度。
- **解释**：如果λ值过大，可能会限制对新任务的学习；如果λ值过小，旧任务的知识可能会被遗忘。

### 11. EWC如何在Atari游戏中实现？
- **答案**：在强化学习设置中，EWC用于动态保护在不同游戏中的知识，允许代理在多个游戏之间切换而不遗忘以前的游戏策略。
- **解释**：代理在学习每个游戏时，可以利用EWC防止其遗忘先前学习的游戏策略。

### 12. 为什么在深度学习中，权重的过度参数化是有利的？
- **答案**：过度参数化增加了找到相似任务解决方案的机会，使得新任务的学习不会对旧任务的性能造成显著损害。
- **解释**：这就像是在有更多房间的房子里，每个房间可以用于不同的功能，不会干扰其他房间的用途。

### 13. 什么是“同步存储”（Episodic Memory）？
- **答案**：是指在训练期间保存所有任务的数据，以便在后续任务中可以重放这些数据。
- **解释**：类似于在学习新知识时，不时地复习之前学过的内容，以帮助记忆。

### 14. 论文中提到的“任务特异性突触巩固”是什么？
- **答案**：指的是通过选择性地增强与旧任务相关的突触来巩固旧知识。
- **解释**：这类似于我们在学习一门语言时，通过多次重复来加深对单词的记忆。

### 15. EWC的局限性是什么？
- **答案**：EWC依赖于对Fisher信息的近似，可能会低估某些权重的重要性，导致模型对某些任务的记忆不够可靠。
- **解释**：就像我们在估计某个项目的风险时，可能只考虑了明显的因素，而忽略了潜在的风险。

### 16. 在MNIST实验中，如何评估EWC的效果？
- **答案**：通过比较不同训练策略下，模型在多个任务上的测试准确率来评估EWC的性能。
- **解释**：比如，观察模型在每次训练任务后的表现，检查是否能维持旧任务的高准确率。

### 17. 什么是“权重固化”在生物神经网络中的作用？
- **答案**：权重固化有助于在学习新任务时保持旧知识的稳定性，防止忘记之前的技能。
- **解释**：这就像大脑中的记忆，如果记忆保持稳定，学习新东西就不会丢失旧的知识。

### 18. EWC与其他正则化方法（如L2正则化）有何不同？
- **答案**：EWC根据权重的重要性进行选择性约束，而L2正则化对所有权重施加相同的约束。
- **解释**：L2正则化像是对每个权重施加相同的绳子，而EWC则是根据权重的重要性调整绳子的紧度。

### 19. 在深度学习中，模型的“记忆”是如何实现的？
- **答案**：通过使用EWC或其他类似机制来保护重要的网络参数，使其在学习新任务时不被轻易修改。
- **解释**：就像我们在做笔记时，某些重要的点会特别标记，以便在后续学习时不遗忘。

### 20. 如何利用EWC解决实际应用中的灾难性遗忘问题？
- **答案**：通过逐步训练模型，使其能够在保留旧知识的基础上，学习新知识，适应不断变化的任务需求。
- **解释**：比如，一个聊天机器人需要在学习新对话模式的同时，保持对旧对话的理解。

### 21. 在不同任务之间，EWC如何确保网络的共享表示？
- **答案**：通过评估任务间Fisher信息矩阵的重叠程度，EWC可以有效地在相似任务之间共享权重。
- **解释**：就像在处理多个项目时，找出共享资源，以提高工作效率。

### 22. 如何理解EWC中的高斯近似？
- **答案**：EWC将旧任务的后验分布近似为高斯分布，使得计算参数的更新变得更为简单。
- **解释**：这就像是在估计某个数据点的分布时，假设其服从正态分布，以便于分析。

### 23. EWC在任务切换时如何计算损失？
- **答案**：在每次任务切换时，EWC会计算当前任务的损失，并加上一个关于旧任务的惩罚项，以保持旧知识。
- **解释**：这相当于在考试时，先完成当前的题目，同时复习旧的知识点，以保持对以前内容的掌握。

### 24. 在强化学习中，EWC是如何帮助代理记忆旧任务的？
- **答案**：EWC通过对代理的网络参数施加约束，确保代理在学习新游戏时不会遗忘之前学会的游戏策略。
- **解释**：比如，一个棋手在学习新棋局时，依然能运用之前的开局策略。

### 25. 在多任务学习中，EWC如何处理任务的相关性？
- **答案**：通过分析任务之间的Fisher信息重叠，EWC能够决定哪些权重需要保持固定，以便最大限度地利用共享的信息。
- **解释**：如同在处理多个项目时，找出共享资源，以提高工作效率。

### 26. 什么是“长短期记忆机制”在EWC中的体现？
- **答案**：EWC通过保持重要参数的稳定性，实现短期和长期任务知识的结合，类似于生物神经网络的记忆机制。
- **解释**：就像我们在学习过程中，不断加深对知识的理解，同时保留基础知识。

### 27. EWC在实际应用中是否存在计算负担？
- **答案**：EWC的计算复杂度是线性的，能够有效地与深度学习模型结合，而不会显著增加计算成本。
- **解释**：这意味着在训练大型模型时，EWC不会让计算变得过于复杂。

### 28. EWC是否适用于所有类型的深度学习任务？
- **答案**：尽管EWC在许多任务中表现出色，但仍需根据具体任务调整参数和策略，以确保最佳效果。
- **解释**：不同的任务可能有不同的特点，因此需要定制化的方法。

### 29. EWC的未来发展方向是什么？
- **答案**：未来可能会结合更复杂的贝叶斯推断方法，改进权重的不确定性估计，以进一步增强其效果。
- **解释**：例如，可能会利用更多的生物启发机制，使得EWC在处理复杂任务时更有效。

### 30. 总结一下EWC的核心贡献是什么？
- **答案**：EWC通过引入弹性权重固化的方法，解决了神经网络在连续学习中的灾难性遗忘问题，为实现人工智能的持续学习提供了新的思路。
- **解释**：EWC的成功应用为未来的AI系统提供了更强大的学习能力，使其能够在变化的环境中不断进步。

