
# [Learning Fast and Slow for Online Time Series Forecasting](https://arxiv.org/abs/2202.11672)

----

<img width="1366" alt="Screenshot 2025-04-02 at 12 57 52 AM" src="https://github.com/user-attachments/assets/fb593fc1-5936-4cc9-906b-daed785c88ef" />

-----

## 研究背景

深度神经网络在时间序列预测中取得成功，但多基于 **批量训练（batch learning）**，假设数据静态。实际应用中数据通常是流式的，并伴随 **概念漂移（concept drift）**。

在线训练存在两大挑战：

- 对新数据适应慢（学习效率低）；

- **灾难性遗忘**，无法有效记住或利用过去的模式。

新框架 **FSNet (Fast and Slow learning Network)**，启发来自 **神经科学中的 CLS 理论（Complementary Learning Systems）**。是一种面向 **非平稳环境下时间序列预测任务**的连续学习框架，通过模拟人脑“快与慢”的互补机制，实现对新概念的快速适应与对旧知识的有效记忆。

FSNet 包括两个互补模块：

1. **Per-layer Adapter**：每一层的轻量化快速适应器，支持快速局部学习；

2. **Associative Memory**：关联记忆模块，用于存储和回忆重复出现的历史适应行为。

## 算法

### 1. 架构

![image](https://github.com/user-attachments/assets/a81b54fe-2fb4-48ed-b910-03b034a70fef)

（FSNet 中的每个卷积滤波器都配备了一个适配器和关联存储器，通过监控主干的梯度 EMA 来促进快速适应新旧模式。）

主干网络为 **Temporal Convolutional Network (TCN)**， 在每一层加上：**适配器 φ<sub>l</sub>** + **记忆模块 M<sub>l</sub>**；

总参数集为 ω = {θ<sub>l</sub>, φ<sub>l</sub>}<sup>L</sup>，总记忆集为 M = {M<sub>l</sub>}<sup>L</sup>。

### 2. 快速适应机制（Fast Adaptation）

使用滑动平均（EMA）平滑每层梯度：  

![image](https://github.com/user-attachments/assets/71ff4113-1926-4e4a-8d69-8361b410d162)

生成适配系数：

权重适配：α<sub>l</sub>；
特征适配：β<sub>l</sub>；

应用方式：

![image](https://github.com/user-attachments/assets/fd7777ef-8cb5-476e-a2c9-42fa30f8691b)

### 3. 重复模式记忆机制（Associative Memory）

存储学习过程中遇到的重复事件的适应系数。因此，单独的适配器可以处理短时间尺度上的快速变化，而联想存储器可以促进重复模式的学习

存储适配向量 u（= [α<sub>l</sub>, β<sub>l</sub>]）以记忆过去应对某一模式的行为

当**触发条件**满足：

![image](https://github.com/user-attachments/assets/77cb54a1-2a15-4361-8623-b023ef4c0cdd)

- 从 M<sub>l</sub> 中**读取最相似记忆**；

适配器-内存交互机制 由于当前的适应系数可能无法捕获整个事件，这可能跨越几个样本，因此我们 使用 adaptation coefficients 的 EMA 执行内存读写作，以完全捕获当前 pattern

- 当前适配器参数与回忆融合：  

![image](https://github.com/user-attachments/assets/fc062fd1-4e88-4c33-8d52-f86979077482)

- 用 outer product 写入更新：  

![image](https://github.com/user-attachments/assets/4e4cd487-e90e-40b7-af7b-4e1726f946b0)

## FSNet 应用

**时间序列在线预测**被形式化为 **无任务边界（task-free）连续学习问题**

1. 每段局部平稳序列视为一个“任务”，FSNet可处理新旧任务无缝切换

2. **不依赖任务切换标记点**

3. 强调对当前样本的利用和过去知识的回忆。

应用场景： 
- 电力负荷预测（ECL 数据集）；
- 气象建模（WTH 数据集）；
- 交通预测（Traffic）；
- 高频交易信号等实时智能系统。

## 结论

我们研究了在非平稳环境中训练深度神经网络进行在线时间序列预测的局限性，在这些环境中，它们缺乏快速适应新的或重复出现的模式的能力。然后，我们通过将用于持续学习的 CLS 理论扩展到在线时间序列预测来提出快速和慢速学习网络 （FSNet）。FSNet 通过两个关键组件增强了神经网络主干：（i） 用于适应最近变化的适配器;（ii） 用于处理循环模式的联想记忆。此外，适配器与其内存稀疏交互以存储、更新和检索重要的重复模式，以便将来学习此类事件。广泛的实验表明，FSNet 能够处理各种类型的概念漂移，从而在真实世界和合成时间序列数据中取得有希望的结果。


