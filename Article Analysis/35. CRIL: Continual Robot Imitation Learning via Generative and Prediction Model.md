
# [CRIL: Continual Robot Imitation Learning via Generative and Prediction Model](https://arxiv.org/abs/2106.09422)

----

<img width="1366" alt="Screenshot 2025-04-02 at 1 00 15 AM" src="https://github.com/user-attachments/assets/97975435-f491-4b0e-9880-d44e45a352b7" />

-----

## **研究背景**

CRIL 将“生成式回放”首次与机器人模仿学习结合，实现了无需海量存储的持续学习框架。其核心在于首帧生成 + 预测式轨迹重建，使旧技能得以在“脑内模拟”中重练。然而生成质量和物理逼真度限制了可扩展性。

研究了如何实现持续模仿学习能力，使机器人能够不断地逐个学习新任务，从而减轻多任务 IL 的负担，同时加速新任务学习的过程。我们提出了一种新的轨迹生成模型，该模型采用生成对抗网络和动力学感知预测模型，从新任务学习过程中的所有学习任务中生成伪轨迹。

![image](https://github.com/user-attachments/assets/64730abb-dc57-402e-9fb5-7b001b1d49dc)

（重放学习任务的伪数据，并将它们与新任务的真实数据交错以更新其网络）

- 提出首帧 + 预测式 Generative Replay 机制，显著降低回放成本。  

- 给出完整算法 CRIL（Continual Robot Imitation Learning）及理论 / 实验分析。
   
## 算法

<img width="997" alt="35_Pic" src="https://github.com/user-attachments/assets/ef38b5b8-0feb-48ce-a9d0-d7ea79ccdc90" />

不再把旧任务数据原封不动存盘，而是用“生成式回放”（Generative Replay, GR）动态合成旧数据。  

为了在视觉-控制任务中做到这一点，作者同时维护三张网络：  

① 策略网络 πθ      —— 生成动作  

② 首帧生成器 Gψ    —— 造出任务场景的第一张图像  

③ 预测网络 Pφ      —— 根据动作把首帧滚动出完整轨迹  

学新任务时，用真实演示 + 合成旧轨迹的混合数据共同训练三张网络，实现“边学边复习”。  

## 应用

多阶段机器人操作（抓取→搬运→组装…）；  

服务机器人、工业协作臂等需要不断注入新技能且内存受限的系统。  

优点：  

1） 仅保存 3 个网络的权重，显存 / 硬盘占用与任务数无关  

2） 通过合成轨迹“温习”旧任务，减少灾难性遗忘

3） 不需在真环境回放旧任务，节省交互成本



