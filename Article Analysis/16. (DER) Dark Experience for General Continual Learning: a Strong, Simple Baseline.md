# DER - [Dark Experience for General Continual Learning: a Strong, Simple Baseline](https://arxiv.org/abs/2004.07211)

----

<img width="1159" alt="Screen Shot 2024-10-16 at 1 01 38 PM" src="https://github.com/user-attachments/assets/cefa519a-d93a-4907-a57d-e544b59fc919">

----

Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, and Simone Calderara. 2020. Dark experience for general continual learning: a strong, simple baseline. NIPS 33 (2020), 15920–15930.

---

# 核心要点

1. 提出了一种新的基线方法DER，通过重放logits 而非真实标签来增强记忆保留能力。
2. 满足 GCL 的主要要求：在线学习、恒定的内存占用、不依赖任务边界、没有任务标识的推理。
3. 提出了 MNIST-360 数据集，结合平滑和突变的分布变化，模拟真实世界的增量学习场景。

## DER算法

DER的主要目标是通过 **重放模型在训练过程中的输出（logits）** 来减轻灾难性遗忘。它结合了传统的 **经验重放（Experience Replay）** 方法和 **知识蒸馏（Knowledge Distillation）** 技术，通过保留logits而不是实际的类别标签来增强对先前知识的保持。

### DER算法的步骤

1. **初始化**：设置一个固定大小的重放缓冲区，用于存储训练过程中样本的logits和输入数据。

2. **训练过程**：

- 对于当前训练样本，计算其logits输出，并使用该输出更新模型参数。
- 从重放缓冲区中采样一些存储的样本，计算其logits与当前模型输出之间的差异（通常使用欧氏距离或KL散度），并将其作为一个正则化项加入损失函数。
- 使用优化算法（如SGD）更新模型参数，使其同时优化当前任务的损失和重放样本的正则化损失。

3. **缓冲区更新**：采用 **Reservoir Sampling** 策略更新重放缓冲区。每当有新的样本加入时，以一定概率替换掉缓冲区中的旧样本，以确保样本的代表性。

4. **在线推理**：在推理过程中，不需要知道任务的标识，直接对输入进行预测。

### DER++的增强步骤

DER++是在DER的基础上增加了一项基于真实标签的损失正则项，用来增强模型对存储样本的拟合，尤其在数据分布突然变化时可以提高稳定性。

<img width="704" alt="Screen Shot 2024-10-16 at 1 24 25 PM" src="https://github.com/user-attachments/assets/a7fb4688-5669-4ab8-a943-3b36db9f4f4f">

### DER在增量学习领域的应用

DER主要应用于增量学习中的以下场景：

1. **任务增量学习（Task-Incremental Learning）**：任务明确分割且在推理时已知任务标识，DER可用于保留每个任务的logits，以避免忘记先前任务的知识。

2. **类别增量学习（Class-Incremental Learning）**：类别在不同任务中逐渐引入，DER可以在没有任务标识的情况下利用重放机制来保持先前学习的类别知识。

3. **域增量学习（Domain-Incremental Learning）**：不同任务之间的输入分布不同，但类别集保持不变，DER通过重放样本logits来应对输入分布的变化。

### DER算法的缺陷和不足

尽管DER在实验中展示了优异的性能，但仍存在一些缺陷和不足：

1. **缓冲区大小限制**：DER依赖于有限大小的缓冲区来存储样本的logits，当任务数目增多时，缓冲区内可能无法存储足够的样本，导致性能下降。

2. **数据顺序敏感性**：DER对于样本的顺序较为敏感，如果新数据分布变化剧烈，可能导致旧任务的logits偏离其最优解，从而影响模型的稳定性。

3. **对存储样本的选择性不足**：DER采用随机的Reservoir Sampling策略，可能无法保证存储的样本对当前任务和先前任务的平衡。

4. **计算开销**：在大型数据集上，计算每个样本的logits匹配损失会增加计算开销，尤其在缓冲区较大时。

### 改进建议

针对上述不足，可以提出以下改进建议：

1. **动态调整缓冲区大小**：可以根据任务数量或任务复杂度动态调整缓冲区大小，使得更多重要样本能够被存储，避免内存资源的浪费。

2. **基于重要性的样本选择策略**：引入样本的重要性度量，如样本的置信度或新任务的难度，对高重要性的样本赋予更高的存储概率，以增强缓冲区样本的代表性。

3. **多级缓冲区机制**：采用多级缓冲区结构，将短期内的重要样本存储在高优先级的缓冲区中，而较长时间的样本则存储在低优先级的缓冲区中，通过分层重放机制更好地平衡任务间的知识保持。

4. **结合更多的正则化策略**：除了logits匹配，还可以结合参数正则化（如EWC）或特征匹配等方法，以多重方式减轻灾难性遗忘。

DER通过重放logits的方法在增量学习领域展现了很强的性能，特别是在一般性的连续学习场景中，其简单的实现和良好的表现使其成为一个强大的基线方法。然而，随着任务数量和数据复杂度的增加，其在缓冲区管理和样本选择上的不足也逐渐显现。通过改进缓冲区机制、引入样本选择策略等，可以进一步提升DER在增量学习中的应用效果。

-----


# 精读笔记

### 1. 什么是“灾难性遗忘”（Catastrophic Forgetting）？为什么它是连续学习中的一个挑战？
**答案**：灾难性遗忘是指神经网络在学习新任务时会迅速忘记之前学到的任务知识的现象。这是由于传统神经网络的参数更新是全局的，新任务的训练会覆盖旧任务的记忆。它在连续学习中是一个挑战，因为模型需要不断学习新知识而不丢失旧的知识。

### 2. 论文提出的“Dark Experience Replay”（DER）是什么？它如何缓解灾难性遗忘？
**答案**：DER是一种基于知识蒸馏的重放方法，通过对之前训练样本的logits（网络输出的未归一化得分）进行重放来保持一致性。它通过存储模型在训练过程中某些时刻对样本的logits响应，避免遗忘旧任务的知识。

### 3. 知识蒸馏在DER中的作用是什么？
**答案**：知识蒸馏用于保持模型在训练过程中的一致性，DER通过匹配存储的logits来约束新任务的学习，从而保留过去的知识。

### 4. DER与传统的Experience Replay（ER）的主要区别是什么？
**答案**：传统的ER存储样本的真实标签，而DER存储样本的logits。相比之下，DER利用soft label（软标签）包含更多信息，可以更好地缓解灾难性遗忘。

### 5. 为什么论文称DER为“Dark Experience Replay”？
**答案**：名称中的“Dark”源自于“Dark Knowledge”的概念，即由softmax产生的概率分布包含的隐性信息。DER通过重放这些logits来保持模型的过去知识。

### 6. 什么是General Continual Learning（GCL）？与传统的连续学习场景有什么不同？
**答案**：GCL是一种更通用的连续学习场景，没有明确的任务边界，数据分布和类别可能逐渐或突然变化。相比之下，传统的连续学习场景通常假设任务是明确分割的，并且任务边界已知。

### 7. DER如何满足GCL的要求？
**答案**：DER通过使用在线学习、不依赖任务边界和恒定的内存占用来满足GCL的要求。它可以在不需要任务标识的情况下进行推理。

### 8. 论文中提到的“MNIST-360”是什么？它是如何被设计用来测试GCL的？
**答案**：MNIST-360是一个新提出的评估设置，将MNIST数据集中的数字分类任务与逐渐增加的图像旋转相结合，模拟数据分布的平滑和突然变化，以测试模型应对GCL场景的能力。

### 9. 论文中使用的哪些标准连续学习评估数据集？为什么选择这些数据集？
**答案**：使用的数据集包括Permuted MNIST、Rotated MNIST、Sequential CIFAR-10和Sequential Tiny ImageNet等。这些数据集通过改变任务的类别或域分布模拟连续学习场景，考察方法的泛化能力。

### 10. DER如何利用“logits匹配”进行优化？与传统的损失函数优化有何不同？
**答案**：DER通过最小化存储的logits和当前模型输出之间的差异（如欧氏距离）来优化，传统的损失函数通常是基于真实标签的交叉熵。logits匹配可以防止模型过度拟合当前任务，从而减轻灾难性遗忘。

### 11. 什么是“Knowledge Distillation”？DER中是如何应用的？
**答案**：知识蒸馏是通过一个教师模型的输出引导学生模型的学习。DER通过将之前任务的logits作为软标签，指导模型保持旧任务的输出一致性。

### 12. DER++与DER有何不同？增加的正则项的作用是什么？
**答案**：DER++在DER的基础上增加了一项正则化项，用来增强对于存储样本的真实标签的拟合。当输入数据分布突然改变时，这种方法有助于提高模型的稳定性。

### 13. 在算法1中，DER++的更新规则是什么？
**答案**：DER++的更新规则是在损失函数中包含两个项：一个是logits匹配项，另一个是基于存储样本真实标签的交叉熵损失。

### 14. 什么是“Rehearsal-based Methods”？DER如何分类？
**答案**：Rehearsal-based方法通过存储过去的样本或经验来减轻灾难性遗忘。DER属于这种方法，但它存储的是样本的logits，而非真实标签。

### 15. 在论文的实验中，DER如何在不同数据集上的表现？
**答案**：实验显示，DER在大多数标准的连续学习设置中表现优异，尤其是在内存受限的情况下，其性能明显优于其他方法。

### 16. 为什么论文认为GEM和MER不适用于在线的GCL场景？
**答案**：GEM和MER需要任务边界来存储样本或进行优化约束，这与GCL场景的假设不符，因为GCL场景中任务边界是模糊的或未知的。

### 17. DER如何处理突然的分布变化？为什么它在这种情况下比其他方法表现更好？
**答案**：DER通过存储不同时间点的logits可以在数据分布发生突然变化时提供更好的正则化效果，避免模型过拟合新任务。

### 18. 什么是“Reservoir Sampling”？DER为什么采用这种策略？
**答案**：Reservoir Sampling是一种在数据流中随机采样的算法。DER使用这种方法来保持存储样本的代表性，而无需知道数据流的长度。

### 19. DER在任务之间共享相同的网络参数，这对连续学习有何影响？
**答案**：共享参数意味着新任务的训练会影响旧任务的性能，但DER通过logits匹配限制参数的变化，以减少这种负面影响。

### 20. 在模型分析中，DER对训练过程的优化轨迹有何影响？
**答案**：DER的logits匹配策略使训练过程更加平稳，防止模型偏离最佳的泛化区域，从而提高模型的稳定性和性能。

### 21. 论文中提到的“Weighted Cumulative Sum of the Fisher Matrix Energy”用于评估什么？
**答案**：该指标用于评估训练过程中参数变化的累积量，以反映模型的泛化能力和优化轨迹的平稳性。

### 22. DER的“Soft Targets”和“Hard Targets”有什么区别？为什么使用Soft Targets？
**答案**：Soft Targets是由softmax输出的概率分布，而Hard Targets是实际的类别标签。Soft Targets包含了类别之间的相似性信息，使用它可以更好地保持旧任务的知识。

### 23. 为什么论文中提到在持续学习中“logits的匹配比概率空间的匹配更好”？
**答案**：在logits空间进行匹配可以避免softmax压缩导致的信息损失，因为softmax将信息从高维空间映射到低维概率分布。

### 24. DER和DER++的内存消耗如何控制？为什么重要？
**答案**：DER和DER++使用恒定大小的缓冲区来存储过去的logits，避免了内存消耗随任务数量增长的问题。这对于实际应用中资源受限的情况尤为重要。

### 25. 论文为什么要设计MNIST-360这种数据集？
**答案**：MNIST-360设计用来模拟实际应用中的平滑和突然的分布变化，为模型的GCL性能提供更具挑战性的测试场景。

### 26. 为什么PNN不适用于Domain-IL和Class-IL场景？
**答案**：PNN为每个任务实例化一个子网络，在Domain-IL和Class-IL中无法处理类别或域内的分布变化，也无法在没有任务标识的情况下做出预测。

### 27. 为什么使用欧氏距离来计算KL散度？
**答案**：使用欧氏距离可以避免在softmax空间进行匹配时的信息损失，并且计算简单，易于优化。

### 28. DER如何在高难度的数据集（如Tiny ImageNet）上表现？
**答案**：在高难度数据集上，DER表现优异，尤其是在缓冲区较小的情况下，因为它更好地利用了存储的logits信息来保持旧任务的知识。

### 29. 什么是“GCL合规性”？DER如何满足这些要求？
**答案**：GCL合规性是指方法是否能够在线学习、使用恒定内存、不依赖任务边界并在推理时无需任务标识。DER满足了这些要求，因为它不依赖任务边界，使用固定大小的缓冲区，并且能够在没有任务标识的情况下工作。

### 30. 论文中的实验设置是如何设计的？为什么要统一批量大小和优化算法？
**答案**：实验设置统一了批量大小和优化算法（SGD），以确保不同方法之间的公平比较。统一批量大小可以避免不同方法更新步数不一致的问题。

