# [ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via Chart-to-Code Generation](https://arxiv.org/abs/2406.09961)

----

<img width="1396" alt="Screenshot 2025-03-24 at 11 35 45 PM" src="https://github.com/user-attachments/assets/962ff257-5afb-4588-a36a-b4497b373bcd" />

----

## 研究背景
1. **研究问题:** 这篇文章旨在评估大型多模态模型（LMMs）在图表到代码生成任务中的跨模态推理能力。具体来说，研究了LMMs如何通过视觉理解和代码生成能力，将给定的图表转换为可执行的代码。
2. **研究难点:** 该问题的研究难点包括：视觉理解、代码生成和跨模态推理的高度整合。现有的代码生成基准主要依赖于文本输入，而在实际应用中，人类通常需要结合视觉信息和文本指令来完成编码任务。
3. **相关工作:** 相关工作包括ChartQA、Chart-to-Text、ChartSumm等图表理解基准，以及HumanEval、MBPP等代码生成基准。然而，这些基准主要依赖于单模态输入，未能充分反映现实场景中的多模态需求。

## 研究方法
这篇论文提出了一个名为ChartMimic的新基准，用于评估LMMs在图表到代码生成任务中的跨模态推理能力。具体来说，研究方法包括以下几个方面：

1. **任务定义:** 给定一个图表X和文本指令I，LMMs被期望生成能够重现图表的代码C：
   
$$
   C = f(X, I)   
$$


   具体任务包括：
   • **Direct Mimic:** LMMs直接生成能够重现给定图表的代码。
   • **Customized Mimic:** LMMs根据指令中的新数据生成新的图表代码，同时保持原始图表的美学和设计。

2. **数据收集和标注:** 
   • 从arXiv等来源收集了约174,100张图表，并通过多轮筛选和专家评估，最终选择了4,800张高质量图表。
   • 每张图表都配有文本指令和对应的代码，形成了（图表，指令，代码）三元组。

3. **多层次评估指标:** 
   • **高级指标:** 使用GPT-4o对生成的图表和原始图表进行相似性评分，评分范围为0到100。
   • **低级指标:** 包括文本、布局、类型和颜色四个方面的F1分数。通过代码追踪器记录生成代码的执行过程，提取这些元素并进行比较。

## 实验设计
实验设计包括以下几个方面：

1. **基线模型:** 评估了17个广泛使用的专有和开源模型，包括GPT-4o、Claude-3-opus、GeminiProVision等。
2. **数据划分:** 将4,800个三元组分为测试集和测试小数据集，测试小数据集包含1,200个样本，用于快速模型验证。
3. **实验配置:** 对于开源模型，设置温度参数τ=0.1；对于专有模型，设置温度参数τ=0。所有模型的最大生成长度设置为4096。

## 结果与分析
实验结果表明：

1. **模型性能:** 
   • 在专有模型中，GPT-4o在Direct Mimic和Customized Mimic任务中的总体得分分别为81.2和83.2。
   • 在开源模型中，InternVL2-Llama3-76B表现最佳，总体得分为58.5（Direct Mimic）和64.7（Customized Mimic）。
   • 开源模型与专有模型之间存在显著性能差距，表明当前开源模型在复杂视觉理解、代码生成和跨模态推理方面仍有改进空间。

2. **不同复杂度水平的性能:** 
   • 随着任务难度的增加，所有模型的性能均有所下降。例如，GPT-4o在简单、中等和困难级别的Direct Mimic任务中的得分分别为86.5、77.7和74.8。
   • 提供额外数据可以提升模型在简单任务中的性能，但在困难任务中，即使提供额外数据，模型性能仍可能下降。

3. **不同提示方法的影响:** 
   • 自我反思（SelfReflection）提示方法显著提升了GPT-4o和InternVL2-Llama3-76B的性能，表明系统2推理在处理复杂任务中的重要性。
   • 提示方法如HintEnhanced和Scaffold对模型性能的提升有限，甚至可能导致性能下降。

4. **与人类评估的相关性:** 
   • 高级指标和低级指标与人类评估的相关系数分别为0.7041和0.7681，表明多层次评估指标的有效性。

## 总体结论
这篇论文提出了ChartMimic基准，用于评估LMMs在图表到代码生成任务中的跨模态推理能力。研究表明，当前的LMMs在该任务中仍面临显著挑战，尤其是在复杂图表的处理和细粒度视觉元素识别方面。未来的研究可以通过改进提示策略和增强模型的视觉理解能力来缩小开源模型与专有模型之间的差距。
